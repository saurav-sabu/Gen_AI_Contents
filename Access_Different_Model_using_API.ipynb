{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face API"
      ],
      "metadata": {
        "id": "KU1znZqaSUAc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRdyDEI9KwP-"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Hugging Face API key"
      ],
      "metadata": {
        "id": "I7OhtZK5rG2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TOKEN = userdata.get('HUGGING_FACE_API_KEY')"
      ],
      "metadata": {
        "id": "ZLqzEdJvVDi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the model ID and the base URL for the API"
      ],
      "metadata": {
        "id": "v3xfjSDjrQrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"google/gemma-7b\""
      ],
      "metadata": {
        "id": "Z9NVr23VVPX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://api-inference.huggingface.co/models/\"\n",
        "model_url = base_url + model_id"
      ],
      "metadata": {
        "id": "WbiHzrxwWLVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up the authorization headers"
      ],
      "metadata": {
        "id": "KQ7RO3YqrWMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}"
      ],
      "metadata": {
        "id": "HrdG_c5TYrKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the query function"
      ],
      "metadata": {
        "id": "-6DY9lnLraht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def query(payload):\n",
        "  response = requests.post(model_url,headers=headers,json=payload)\n",
        "  return response.json()"
      ],
      "metadata": {
        "id": "bGMAHNITYUnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the question payload"
      ],
      "metadata": {
        "id": "HoQ1D8LfrfOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = {\n",
        "    \"inputs\":\"Who is the CEO of Tesla?\"\n",
        "}"
      ],
      "metadata": {
        "id": "EpFkTgEqZPsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the output from the model"
      ],
      "metadata": {
        "id": "H-yPyZhLrlyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = query(question)"
      ],
      "metadata": {
        "id": "0MQhJ3efZZPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print the generated text"
      ],
      "metadata": {
        "id": "o5uQPWUxrtnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDBZtlG8Ze6U",
        "outputId": "201d08f9-584e-4843-ddd0-daf79e0ff707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Who is the CEO of Tesla? Elon Musk has been called a lot of things: genius, a visionary, the real-life Iron Man, and, thanks to his utterances in an hours-long appearance before parliamentary committee in the United Kingdom mining status, a “punk rock god.” Musk has built a $60 billion company into the biggest startup in modern history, a feat he accomplished largely on the basis of his own technical abilities. <em>Time</em> named him as most influential person in the world, while <em>Fortune</em>'}]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XaQm4LDZiVL",
        "outputId": "54aae74d-8739-4d79-c85c-d5ad6d751812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who is the CEO of Tesla? Elon Musk has been called a lot of things: genius, a visionary, the real-life Iron Man, and, thanks to his utterances in an hours-long appearance before parliamentary committee in the United Kingdom mining status, a “punk rock god.” Musk has built a $60 billion company into the biggest startup in modern history, a feat he accomplished largely on the basis of his own technical abilities. <em>Time</em> named him as most influential person in the world, while <em>Fortune</em>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output[0].get(\"generated_text\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXz67J2qZm6D",
        "outputId": "6a3c2457-3161-42d4-a192-e302039a62d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who is the CEO of Tesla? Elon Musk has been called a lot of things: genius, a visionary, the real-life Iron Man, and, thanks to his utterances in an hours-long appearance before parliamentary committee in the United Kingdom mining status, a “punk rock god.” Musk has built a $60 billion company into the biggest startup in modern history, a feat he accomplished largely on the basis of his own technical abilities. <em>Time</em> named him as most influential person in the world, while <em>Fortune</em>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mixstral\n",
        "LLAMA 2\n",
        "Zephyr\n",
        "Claude"
      ],
      "metadata": {
        "id": "Hghax7H3aRgi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open AI API"
      ],
      "metadata": {
        "id": "8waUS0z7LorT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install the OpenAI package"
      ],
      "metadata": {
        "id": "d3QOzBZBsAwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOZwYqjTTVcw",
        "outputId": "d530e400-f80c-401c-e7ce-671f2d90d094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/320.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/320.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Text Generation"
      ],
      "metadata": {
        "id": "z9UyK_nCfFXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the OpenAI module"
      ],
      "metadata": {
        "id": "_Q2mCLXosGAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "bW0ChzOxaEFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve the OpenAI API key from Google Colab user data"
      ],
      "metadata": {
        "id": "WtIHC95ZsL0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPEN_AI_API_KEY = userdata.get('OPEN_AI_API_KEY')"
      ],
      "metadata": {
        "id": "tW0sYhEETfXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the OpenAI client with the API key"
      ],
      "metadata": {
        "id": "EVBqD1WZsQF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=OPEN_AI_API_KEY)"
      ],
      "metadata": {
        "id": "rLQZJ1sNTQ3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate a text completion using the GPT-3.5-turbo model"
      ],
      "metadata": {
        "id": "zJOf4wu3sYV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Tell me about country India?\"}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "nWEMFyRPTqRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print the raw response for debugging"
      ],
      "metadata": {
        "id": "IKz9cTGEseLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-epUzuj0dusu",
        "outputId": "289f55e6-b2af-4df3-a69e-058cd295ae56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-9QU0FSiiDC0Tp2WavPnDrAeSiw4Zm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='India is a diverse country located in South Asia and is the second most populous country in the world. It has a rich history and is known for its cultural heritage, including ancient monuments, temples, and vibrant festivals. India is also famous for its diverse landscapes, which range from the Himalayas in the north to the beaches of Goa in the south. The country is a democratic republic with a federal structure and is known for its varied languages, religions, and cuisines. India has a fast-growing economy and is a major player in industries such as information technology, pharmaceuticals, and agriculture.', role='assistant', function_call=None, tool_calls=None))], created=1716098887, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=118, prompt_tokens=23, total_tokens=141))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSPvoOEKeKor",
        "outputId": "0ab85738-c0a2-4b93-acdd-8b3719098e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletionMessage(content='India is a diverse country located in South Asia and is the second most populous country in the world. It has a rich history and is known for its cultural heritage, including ancient monuments, temples, and vibrant festivals. India is also famous for its diverse landscapes, which range from the Himalayas in the north to the beaches of Goa in the south. The country is a democratic republic with a federal structure and is known for its varied languages, religions, and cuisines. India has a fast-growing economy and is a major player in industries such as information technology, pharmaceuticals, and agriculture.', role='assistant', function_call=None, tool_calls=None)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "dzwykaCMej2_",
        "outputId": "5dd77dc9-2cbf-49e0-e657-86dc1f9da976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'India is a diverse country located in South Asia and is the second most populous country in the world. It has a rich history and is known for its cultural heritage, including ancient monuments, temples, and vibrant festivals. India is also famous for its diverse landscapes, which range from the Himalayas in the north to the beaches of Goa in the south. The country is a democratic republic with a federal structure and is known for its varied languages, religions, and cuisines. India has a fast-growing economy and is a major player in industries such as information technology, pharmaceuticals, and agriculture.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Image Generation"
      ],
      "metadata": {
        "id": "_tgWdn6UfKzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate an image using the DALL-E model"
      ],
      "metadata": {
        "id": "rXl6ugaTslDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=\"AI dominating the world\",\n",
        "  size=\"1024x1024\",\n",
        "  quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "# Extract and print the URL of the generated image\n",
        "image_url = response.data[0].url"
      ],
      "metadata": {
        "id": "ORKf6LcTemAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "MW2pelzlfn4j",
        "outputId": "1e59bad9-b799-4377-c313-09d6b7b19cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-YiffkTfOC5BITNMsRz07nfNj/user-1vULZf9J1lZWVROqW7qAk96o/img-9xtY5jN6Sz5NoGZZzDqIQcZ5.png?st=2024-05-19T05%3A16%3A36Z&se=2024-05-19T07%3A16%3A36Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-18T14%3A19%3A04Z&ske=2024-05-19T14%3A19%3A04Z&sks=b&skv=2021-08-06&sig=3%2Bgia/SlzqDHOPzavF3GHuL6Q5ocW%2BXwVmkTXbEcGGU%3D'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Vision Model"
      ],
      "metadata": {
        "id": "w1LCFnnzhMQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate a response using the vision model (example assumes a model capable of handling image inputs)\n"
      ],
      "metadata": {
        "id": "w0fcJ5_EswhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": \"https://oaidalleapiprodscus.blob.core.windows.net/private/org-YiffkTfOC5BITNMsRz07nfNj/user-1vULZf9J1lZWVROqW7qAk96o/img-9xtY5jN6Sz5NoGZZzDqIQcZ5.png?st=2024-05-19T05%3A16%3A36Z&se=2024-05-19T07%3A16%3A36Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-18T14%3A19%3A04Z&ske=2024-05-19T14%3A19%3A04Z&sks=b&skv=2021-08-06&sig=3%2Bgia/SlzqDHOPzavF3GHuL6Q5ocW%2BXwVmkTXbEcGGU%3D\",\n",
        "          },\n",
        "        },\n",
        "      ],\n",
        "    }\n",
        "  ],\n",
        "  max_tokens=300,\n",
        ")\n",
        "\n",
        "print(response.choices[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOBNeUonfsfm",
        "outputId": "337e37de-3e0d-4f4d-a5eb-d11da13fa565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The image depicts a futuristic cityscape bustling with advanced technology and innovation. Key elements in the image include:\\n\\n1. **High-Tech Buildings**: The skyscrapers are adorned with digital screens and holographic projections, indicative of a digitally immersive environment.\\n2. **Robots and Drones**: Various types of robots and drones populate the scene. There are humanoid robots, large mechanized robots, and many flying drones.\\n3. **People**: Humans are interacting with the technology around them, indicating a harmonious blend of human activity and technological advancements.\\n4. **Vehicles**: Futuristic autonomous cars are on the roads, suggesting advanced transportation technology.\\n5. **Digital Interfaces**: Large displays and control panels are integrated into the urban landscape, showcasing data and digital interfaces.\\n6. **Greenery**: Despite the high-tech environment, there are patches of greenery, with trees and small green spaces adding balance to the urban setting.\\n\\nOverall, the image portrays a highly advanced, technologically integrated urban future.', role='assistant', function_call=None, tool_calls=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print the raw response for debugging"
      ],
      "metadata": {
        "id": "x1--Ufv5s5rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfcRfvQHg66l",
        "outputId": "0bbd8786-b76b-4329-de70-c3954834b34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image depicts a futuristic cityscape bustling with advanced technology and innovation. Key elements in the image include:\n",
            "\n",
            "1. **High-Tech Buildings**: The skyscrapers are adorned with digital screens and holographic projections, indicative of a digitally immersive environment.\n",
            "2. **Robots and Drones**: Various types of robots and drones populate the scene. There are humanoid robots, large mechanized robots, and many flying drones.\n",
            "3. **People**: Humans are interacting with the technology around them, indicating a harmonious blend of human activity and technological advancements.\n",
            "4. **Vehicles**: Futuristic autonomous cars are on the roads, suggesting advanced transportation technology.\n",
            "5. **Digital Interfaces**: Large displays and control panels are integrated into the urban landscape, showcasing data and digital interfaces.\n",
            "6. **Greenery**: Despite the high-tech environment, there are patches of greenery, with trees and small green spaces adding balance to the urban setting.\n",
            "\n",
            "Overall, the image portrays a highly advanced, technologically integrated urban future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models Available with OpenAI"
      ],
      "metadata": {
        "id": "-0KGEAyElFXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6xMXNcnkNIu",
        "outputId": "e01c0da0-c51c-40ed-e554-b4331ebbc2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<openai.OpenAI at 0x7ef3ecf73df0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve and print the list of available models"
      ],
      "metadata": {
        "id": "N15FjYo5s_HT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.models.list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiPSS0P0kP0F",
        "outputId": "36b0caa3-a7d8-4450-ac07-9f1a801f3b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncPage[Model](data=[Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='gpt-4-1106-vision-preview', created=1711473033, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai')], object='list')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert the list of models to a Pandas DataFrame for better readability"
      ],
      "metadata": {
        "id": "rHz5-_TKtD1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(client.models.list().data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XpaB5j1akp_d",
        "outputId": "1ae7b57c-9f8c-4952-ef27-9307b944317f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    0                      1                2  \\\n",
              "0                      (id, dall-e-3)  (created, 1698785189)  (object, model)   \n",
              "1                     (id, whisper-1)  (created, 1677532384)  (object, model)   \n",
              "2                   (id, davinci-002)  (created, 1692634301)  (object, model)   \n",
              "3                      (id, dall-e-2)  (created, 1698798177)  (object, model)   \n",
              "4             (id, gpt-3.5-turbo-16k)  (created, 1683758102)  (object, model)   \n",
              "5                 (id, tts-1-hd-1106)  (created, 1699053533)  (object, model)   \n",
              "6             (id, gpt-4o-2024-05-13)  (created, 1715368132)  (object, model)   \n",
              "7                      (id, tts-1-hd)  (created, 1699046015)  (object, model)   \n",
              "8                        (id, gpt-4o)  (created, 1715367049)  (object, model)   \n",
              "9                         (id, gpt-4)  (created, 1687882411)  (object, model)   \n",
              "10                   (id, gpt-4-0613)  (created, 1686588896)  (object, model)   \n",
              "11           (id, gpt-3.5-turbo-1106)  (created, 1698959748)  (object, model)   \n",
              "12           (id, gpt-3.5-turbo-0125)  (created, 1706048358)  (object, model)   \n",
              "13  (id, gpt-3.5-turbo-instruct-0914)  (created, 1694122472)  (object, model)   \n",
              "14                (id, gpt-3.5-turbo)  (created, 1677610602)  (object, model)   \n",
              "15       (id, gpt-3.5-turbo-instruct)  (created, 1692901427)  (object, model)   \n",
              "16                        (id, tts-1)  (created, 1681940951)  (object, model)   \n",
              "17           (id, gpt-3.5-turbo-0301)  (created, 1677649963)  (object, model)   \n",
              "18                  (id, babbage-002)  (created, 1692634615)  (object, model)   \n",
              "19           (id, gpt-4-1106-preview)  (created, 1698957206)  (object, model)   \n",
              "20       (id, gpt-4-turbo-2024-04-09)  (created, 1712601677)  (object, model)   \n",
              "21                   (id, tts-1-1106)  (created, 1699053241)  (object, model)   \n",
              "22       (id, text-embedding-3-large)  (created, 1705953180)  (object, model)   \n",
              "23                  (id, gpt-4-turbo)  (created, 1712361441)  (object, model)   \n",
              "24       (id, text-embedding-3-small)  (created, 1705948997)  (object, model)   \n",
              "25           (id, gpt-3.5-turbo-0613)  (created, 1686587434)  (object, model)   \n",
              "26       (id, text-embedding-ada-002)  (created, 1671217299)  (object, model)   \n",
              "27    (id, gpt-4-1106-vision-preview)  (created, 1711473033)  (object, model)   \n",
              "28           (id, gpt-4-0125-preview)  (created, 1706037612)  (object, model)   \n",
              "29         (id, gpt-4-vision-preview)  (created, 1698894917)  (object, model)   \n",
              "30          (id, gpt-4-turbo-preview)  (created, 1706037777)  (object, model)   \n",
              "31       (id, gpt-3.5-turbo-16k-0613)  (created, 1685474247)  (object, model)   \n",
              "\n",
              "                              3  \n",
              "0            (owned_by, system)  \n",
              "1   (owned_by, openai-internal)  \n",
              "2            (owned_by, system)  \n",
              "3            (owned_by, system)  \n",
              "4   (owned_by, openai-internal)  \n",
              "5            (owned_by, system)  \n",
              "6            (owned_by, system)  \n",
              "7            (owned_by, system)  \n",
              "8            (owned_by, system)  \n",
              "9            (owned_by, openai)  \n",
              "10           (owned_by, openai)  \n",
              "11           (owned_by, system)  \n",
              "12           (owned_by, system)  \n",
              "13           (owned_by, system)  \n",
              "14           (owned_by, openai)  \n",
              "15           (owned_by, system)  \n",
              "16  (owned_by, openai-internal)  \n",
              "17           (owned_by, openai)  \n",
              "18           (owned_by, system)  \n",
              "19           (owned_by, system)  \n",
              "20           (owned_by, system)  \n",
              "21           (owned_by, system)  \n",
              "22           (owned_by, system)  \n",
              "23           (owned_by, system)  \n",
              "24           (owned_by, system)  \n",
              "25           (owned_by, openai)  \n",
              "26  (owned_by, openai-internal)  \n",
              "27           (owned_by, system)  \n",
              "28           (owned_by, system)  \n",
              "29           (owned_by, system)  \n",
              "30           (owned_by, system)  \n",
              "31           (owned_by, openai)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-842f60c9-1e61-416f-bf8e-a91c698140cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(id, dall-e-3)</td>\n",
              "      <td>(created, 1698785189)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(id, whisper-1)</td>\n",
              "      <td>(created, 1677532384)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai-internal)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(id, davinci-002)</td>\n",
              "      <td>(created, 1692634301)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(id, dall-e-2)</td>\n",
              "      <td>(created, 1698798177)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(id, gpt-3.5-turbo-16k)</td>\n",
              "      <td>(created, 1683758102)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai-internal)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(id, tts-1-hd-1106)</td>\n",
              "      <td>(created, 1699053533)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(id, gpt-4o-2024-05-13)</td>\n",
              "      <td>(created, 1715368132)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(id, tts-1-hd)</td>\n",
              "      <td>(created, 1699046015)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(id, gpt-4o)</td>\n",
              "      <td>(created, 1715367049)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(id, gpt-4)</td>\n",
              "      <td>(created, 1687882411)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>(id, gpt-4-0613)</td>\n",
              "      <td>(created, 1686588896)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(id, gpt-3.5-turbo-1106)</td>\n",
              "      <td>(created, 1698959748)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(id, gpt-3.5-turbo-0125)</td>\n",
              "      <td>(created, 1706048358)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(id, gpt-3.5-turbo-instruct-0914)</td>\n",
              "      <td>(created, 1694122472)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>(id, gpt-3.5-turbo)</td>\n",
              "      <td>(created, 1677610602)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(id, gpt-3.5-turbo-instruct)</td>\n",
              "      <td>(created, 1692901427)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(id, tts-1)</td>\n",
              "      <td>(created, 1681940951)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai-internal)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>(id, gpt-3.5-turbo-0301)</td>\n",
              "      <td>(created, 1677649963)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>(id, babbage-002)</td>\n",
              "      <td>(created, 1692634615)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>(id, gpt-4-1106-preview)</td>\n",
              "      <td>(created, 1698957206)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>(id, gpt-4-turbo-2024-04-09)</td>\n",
              "      <td>(created, 1712601677)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>(id, tts-1-1106)</td>\n",
              "      <td>(created, 1699053241)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>(id, text-embedding-3-large)</td>\n",
              "      <td>(created, 1705953180)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>(id, gpt-4-turbo)</td>\n",
              "      <td>(created, 1712361441)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>(id, text-embedding-3-small)</td>\n",
              "      <td>(created, 1705948997)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>(id, gpt-3.5-turbo-0613)</td>\n",
              "      <td>(created, 1686587434)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>(id, text-embedding-ada-002)</td>\n",
              "      <td>(created, 1671217299)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai-internal)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>(id, gpt-4-1106-vision-preview)</td>\n",
              "      <td>(created, 1711473033)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>(id, gpt-4-0125-preview)</td>\n",
              "      <td>(created, 1706037612)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>(id, gpt-4-vision-preview)</td>\n",
              "      <td>(created, 1698894917)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>(id, gpt-4-turbo-preview)</td>\n",
              "      <td>(created, 1706037777)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, system)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>(id, gpt-3.5-turbo-16k-0613)</td>\n",
              "      <td>(created, 1685474247)</td>\n",
              "      <td>(object, model)</td>\n",
              "      <td>(owned_by, openai)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-842f60c9-1e61-416f-bf8e-a91c698140cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-842f60c9-1e61-416f-bf8e-a91c698140cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-842f60c9-1e61-416f-bf8e-a91c698140cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7facc3a4-da40-4f02-8b00-4ffba243389a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7facc3a4-da40-4f02-8b00-4ffba243389a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7facc3a4-da40-4f02-8b00-4ffba243389a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 32,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          [\n            \"id\",\n            \"gpt-4-vision-preview\"\n          ],\n          [\n            \"id\",\n            \"gpt-3.5-turbo-instruct\"\n          ],\n          [\n            \"id\",\n            \"text-embedding-3-small\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          [\n            \"created\",\n            1698894917\n          ],\n          [\n            \"created\",\n            1692901427\n          ],\n          [\n            \"created\",\n            1705948997\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          [\n            \"object\",\n            \"model\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          [\n            \"owned_by\",\n            \"system\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google API"
      ],
      "metadata": {
        "id": "cz4TgRwXj39G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve the Google API key from user data"
      ],
      "metadata": {
        "id": "EjYlrISgtjVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "amFN5DhuhBRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the google.generativeai module and configure it with the API key"
      ],
      "metadata": {
        "id": "W5xULqGpto4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "DpfhrAXWmz87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "wLN1aCcim_2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### List all available models and print their names"
      ],
      "metadata": {
        "id": "PQteIoI0ttFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(genai.list_models())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qWXLUHmKnEXP",
        "outputId": "83cd6c2a-24dc-42f0-81f2-c9dc0b76f808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
              "       description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
              "                    'model that supports tuning.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=0.9,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Latest',\n",
              "       description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
              "                    'model.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description='The best image understanding model to handle a broad range of applications',\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description='Mid-size multimodal model that supports up to 1 million tokens',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description='The best image understanding model to handle a broad range of applications',\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       top_p=1.0,\n",
              "       top_k=40)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in genai.list_models():\n",
        "  print(model_name.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "aCoTd1PxnJXv",
        "outputId": "53ac9c3b-e5c6-45b4-8f81-b0afc3488362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001\n",
            "models/text-bison-001\n",
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/aqa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print the names of models that support the \"generateContent\" method"
      ],
      "metadata": {
        "id": "k831OHEjtyyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in genai.list_models():\n",
        "  if \"generateContent\" in model_name.supported_generation_methods:\n",
        "    print(model_name.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "YhQ03NPenYRs",
        "outputId": "31d84e54-c1f0-4c85-e363-b1c16ddfa185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to load a generative model by name"
      ],
      "metadata": {
        "id": "E4GFARLIt_QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name):\n",
        "  llm = genai.GenerativeModel(model_name)\n",
        "  return llm"
      ],
      "metadata": {
        "id": "xSQh4j7-np3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load a text-based generative model"
      ],
      "metadata": {
        "id": "UyUJrzYHuDkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_text = load_model(\"models/gemini-pro\")\n",
        "model_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDhajKVeoVt0",
        "outputId": "3d67b2d6-92f0-4fb0-f0be-f3a22bfd87a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "genai.GenerativeModel(\n",
              "    model_name='models/gemini-pro',\n",
              "    generation_config={},\n",
              "    safety_settings={},\n",
              "    tools=None,\n",
              "    system_instruction=None,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load a vision-based generative model"
      ],
      "metadata": {
        "id": "osO2XeRtuGsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_vision = load_model(\"gemini-pro-vision\")\n",
        "model_vision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQTPUXdQodMT",
        "outputId": "97bff48b-6054-4b44-8524-851304e9ace9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "genai.GenerativeModel(\n",
              "    model_name='models/gemini-pro-vision',\n",
              "    generation_config={},\n",
              "    safety_settings={},\n",
              "    tools=None,\n",
              "    system_instruction=None,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate text content using the text model"
      ],
      "metadata": {
        "id": "He781khyuL6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model_text.generate_content(\"Who is the CEO of Google?\")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "Bxid5zwBojCU",
        "outputId": "303dde37-7013-4ed4-8a1d-cd1dff86d327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=glm.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"text\": \"Sundar Pichai\"\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": 1,\n",
              "          \"index\": 0,\n",
              "          \"safety_ratings\": [\n",
              "            {\n",
              "              \"category\": 9,\n",
              "              \"probability\": 1,\n",
              "              \"blocked\": false\n",
              "            },\n",
              "            {\n",
              "              \"category\": 8,\n",
              "              \"probability\": 1,\n",
              "              \"blocked\": false\n",
              "            },\n",
              "            {\n",
              "              \"category\": 7,\n",
              "              \"probability\": 1,\n",
              "              \"blocked\": false\n",
              "            },\n",
              "            {\n",
              "              \"category\": 10,\n",
              "              \"probability\": 1,\n",
              "              \"blocked\": false\n",
              "            }\n",
              "          ],\n",
              "          \"token_count\": 0,\n",
              "          \"grounding_attributions\": []\n",
              "        }\n",
              "      ]\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print the generated text content"
      ],
      "metadata": {
        "id": "5d4sC0q6uZs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wI76kQmPoqsU",
        "outputId": "51d7c325-44a8-4eff-bf47-5e3c0d68876e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sundar Pichai'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download an image using curl and save it as image.jpg"
      ],
      "metadata": {
        "id": "v6bUt2nDudBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! curl -o image.jpg \"https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/A-Cat.jpg/1200px-A-Cat.jpg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLKf-aEBo_iR",
        "outputId": "b9625ae3-546b-45a6-e71b-ba644191aae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  152k  100  152k    0     0   266k      0 --:--:-- --:--:-- --:--:--  266k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the PIL library to open and manipulate the image"
      ],
      "metadata": {
        "id": "dpFIBrf9ugsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "image = PIL.Image.open(\"image.jpg\")"
      ],
      "metadata": {
        "id": "enLL0FQ8pil3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate text content from the image using the vision model"
      ],
      "metadata": {
        "id": "cJLEHpevuqOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_vision.generate_content(image).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JnAOfezGpbhm",
        "outputId": "31615fc9-7e73-42bd-f6c8-56013acc3ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This is a picture of a cat. The cat is looking at the camera. The cat has green eyes and brown fur. The cat is sitting on a brown surface.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}