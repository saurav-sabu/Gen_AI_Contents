{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nUhsY9tLNq3Z"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the punkt tokenizer models, necessary for sentence tokenization\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_cJdVjJd8Ml",
        "outputId": "e81980b1-7f8f-4abf-9990-e7fee346b9af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder path containing text files\n",
        "folder_path = \"/content/data\"\n",
        "os.listdir(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUaxIosRPZTI",
        "outputId": "9e885ed8-592e-4afe-8fd4-494ed508b775"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['001ssb.txt', '003ssb.txt', '004ssb.txt', '005ssb.txt', '002ssb.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the tokenized sentences\n",
        "corpus = []"
      ],
      "metadata": {
        "id": "GTcyP89IRGmR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over each file in the specified folder\n",
        "for file_name in os.listdir(folder_path):\n",
        "\n",
        "  # Open and read the file with latin-1 encoding\n",
        "  with open(os.path.join(folder_path,file_name),\"r\",encoding=\"latin-1\") as f:\n",
        "    story = f.read()\n",
        "    # Tokenize the story into sentences\n",
        "    sent = sent_tokenize(story)\n",
        "    # Process each sentence and append to the corpus list\n",
        "    for each_sent in sent:\n",
        "      corpus.append(simple_preprocess(each_sent))"
      ],
      "metadata": {
        "id": "vA5EmADpQkoe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the processed corpus\n",
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UDYGic_Q3ea",
        "outputId": "d26435fc-c39c-48e8-e932-e1f2978d3fbb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Word2Vec model with specified parameters\n",
        "model = gensim.models.Word2Vec(\n",
        "    window = 7, # Context window size\n",
        "    min_count = 2, # Ignores all words with total frequency lower than this\n",
        "    workers = 8, # Number of worker threads to train the model\n",
        "    vector_size=200, # Dimensionality of the word vectors\n",
        "    epochs = 10 # Number of training epochs\n",
        ")"
      ],
      "metadata": {
        "id": "t2ooVIDsTrCJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the vocabulary from the corpus\n",
        "model.build_vocab(corpus)"
      ],
      "metadata": {
        "id": "BSZ4LWogYF3g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Word2Vec model\n",
        "model.train(corpus,total_examples = model.corpus_count, epochs = model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUq5EzXmYLKr",
        "outputId": "1230f723-17ed-4242-c5f5-dfb8e1aececa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13141525, 17256380)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of sentences in the corpus\n",
        "model.corpus_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tAqkOvgYakv",
        "outputId": "4d331e8b-6367-490e-ad53-b6affa635643"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "145020"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the length of the corpus (number of sentences)\n",
        "len(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r3nJE9YYv6T",
        "outputId": "eb61bdf9-ad59-4d92-8bec-90c2fcb9400c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "145020"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and print the word vector for the word 'throne'\n",
        "model.wv[\"throne\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGnNTBw_YzU4",
        "outputId": "1e73026c-7999-4392-b5ff-d13b35571438"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.0838825 ,  0.44056413, -0.41874883,  0.48939627, -2.5058315 ,\n",
              "        0.06869879, -2.1402533 ,  1.5708557 ,  0.43150797, -0.48248255,\n",
              "       -0.494238  ,  0.7415264 ,  0.12482452,  0.23526809, -0.59445155,\n",
              "       -0.18206677, -0.05858791,  0.45093322,  1.1207201 ,  1.2146001 ,\n",
              "       -0.39321497,  0.50783753,  0.01975966, -1.2631065 ,  0.31582224,\n",
              "       -2.0704246 ,  0.42457506, -1.5545381 , -0.07198357, -0.43726268,\n",
              "       -0.05650353, -0.41103035, -0.59951645,  1.103096  ,  2.388293  ,\n",
              "        0.60482407,  0.99062324,  0.21562128, -0.7714702 , -0.18797886,\n",
              "        0.5471999 ,  0.640209  ,  1.3643793 ,  1.4811015 ,  1.6434354 ,\n",
              "        0.44364035, -0.46120715,  0.92413795, -1.2920166 , -0.6663538 ,\n",
              "        0.42058116,  0.743507  , -0.16510111, -1.3036686 , -1.9961033 ,\n",
              "        1.2525119 ,  2.1695375 ,  1.3706516 ,  0.06127944, -0.2947577 ,\n",
              "        0.6877137 ,  0.45470208, -0.75404114, -0.9539877 , -0.20409752,\n",
              "       -0.7925026 , -0.05935948,  0.22135358,  0.7138606 , -0.3360263 ,\n",
              "        0.5637047 , -1.4016403 ,  0.64326614, -0.6485267 ,  0.3884393 ,\n",
              "        0.94243836,  0.7859762 , -0.32153776,  0.16641259, -1.1745907 ,\n",
              "       -1.220126  ,  1.6454697 ,  1.3219223 , -0.06634207, -0.18958089,\n",
              "        0.03798024, -0.43780047,  2.0977783 ,  0.28206897, -1.174799  ,\n",
              "       -1.7824008 ,  1.4267305 , -0.13966477, -0.6351957 ,  1.4759768 ,\n",
              "       -0.2470976 ,  0.15827669, -0.06801291,  3.2894459 ,  1.8379525 ,\n",
              "       -1.7075377 ,  2.4262266 , -0.852661  ,  0.9526258 ,  0.08530818,\n",
              "       -0.24306653,  1.1847973 ,  0.8580879 , -1.5692551 , -0.5029889 ,\n",
              "       -1.0935547 , -0.42555833, -1.6698995 ,  0.9105489 , -0.50313705,\n",
              "        2.3157072 , -0.04765891, -1.7384477 ,  1.7923659 ,  0.9061179 ,\n",
              "        0.35382187, -1.5821453 ,  1.9076837 ,  0.9033864 ,  1.3827261 ,\n",
              "       -0.7142559 , -0.9625223 , -2.0895288 , -0.33559453,  1.1763073 ,\n",
              "        0.2593063 ,  0.4841578 , -0.89678586,  0.1152715 ,  0.20489432,\n",
              "       -0.29020938, -0.5372217 , -1.9530127 ,  2.0219486 ,  1.7108029 ,\n",
              "       -0.7441409 ,  2.938434  , -0.5404106 ,  0.96014863, -0.06830902,\n",
              "        1.8797424 , -0.6641068 ,  1.0270277 , -0.7724891 , -0.74828273,\n",
              "       -0.47034717,  0.05896514,  0.55211926,  0.17589305,  0.22740744,\n",
              "        0.63287795, -0.97107434,  1.5528194 , -0.31676066,  1.5404029 ,\n",
              "       -2.4651642 ,  1.3107072 , -1.1706871 ,  1.624975  , -0.57054126,\n",
              "        0.22870818, -0.76634246,  0.05852069,  0.38024867,  0.7071482 ,\n",
              "        0.84208643,  0.29143643,  0.0397766 ,  0.01198315, -0.31088084,\n",
              "       -0.5085652 , -1.4836358 ,  0.7091185 ,  1.6478472 ,  0.26359066,\n",
              "       -0.37170556, -0.4127824 , -0.28709143,  1.198213  ,  1.6099246 ,\n",
              "       -1.2571763 ,  0.9182892 , -0.9361003 , -2.188729  ,  0.27291986,\n",
              "       -1.2426909 , -0.68232685, -0.6580821 , -0.0516071 ,  1.7063416 ,\n",
              "       -0.6848487 , -0.53627616, -0.91794616,  0.4074208 , -0.59870726],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the length of the word vector for 'throne'\n",
        "len(model.wv[\"throne\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nksDME9SZMmo",
        "outputId": "1be2e662-5fdb-4abf-9769-7e290817ff1c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the similarity between 'arya' and 'sansa'\n",
        "model.wv.similarity(\"arya\",\"sansa\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcg7cmSsZQqt",
        "outputId": "3a843403-3f7d-4354-f926-2e0c716d32b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8036768"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the similarity between 'jaime' and 'sansa'\n",
        "model.wv.similarity(\"jaime\",\"sansa\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGqgGvRoZ0BB",
        "outputId": "59b7eea8-6872-41a0-f75d-603bd02b0a9c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.48602727"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the similarity between 'dragon' and 'daenerys'\n",
        "model.wv.similarity(\"dragon\",\"daenerys\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3pN8MyJaA_g",
        "outputId": "45324c61-d845-4030-ab47-da455c694640"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.52477515"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the most similar words to 'king'\n",
        "model.wv.most_similar(\"king\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXhOxBBNaR5O",
        "outputId": "558bf6d5-001e-4af8-bda8-ffa77257abf5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('baratheon', 0.6260662078857422),\n",
              " ('realm', 0.5750989317893982),\n",
              " ('site', 0.5267443060874939),\n",
              " ('ninth', 0.518090009689331),\n",
              " ('royal', 0.5038226246833801),\n",
              " ('feinting', 0.46570757031440735),\n",
              " ('mng', 0.46245068311691284),\n",
              " ('usurper', 0.4613538682460785),\n",
              " ('tourney', 0.4612545967102051),\n",
              " ('conqueror', 0.4485936164855957)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find and print the word that does not match in the list ['jaime', 'cersie', 'jon']\n",
        "model.wv.doesnt_match([\"jaime\",\"cersie\",\"jon\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "PpleMFJdea4d",
        "outputId": "4bc5b394-3eaa-4183-8e08-842d0de20b10"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.keyedvectors:vectors for words {'cersie'} are not present in the model, ignoring these words\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jon'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}